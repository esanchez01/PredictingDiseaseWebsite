<!DOCTYPE HTML>
<!--
	Story by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper" class="divided">

				<!-- One -->
					<section class="banner style2 orient-center content-align-center image-position-center fullscreen onload-image-fade-in onload-content-fade-right">
						<div class="content">
							<h1><b>Predicting Disease Risk<br>Through Machine Learning</b></h1>
							<p class="major">An exploration into the viability of machine learning in disease risk prediction.</p>
							<p><b>Authored By:</b> Enrique Sanchez, Allston Fojas, Michael Sorenson</p>
							<ul class="actions stacked">
								<li><a href="#first" class="button big wide smooth-scroll-middle">View Project</a></li>
							</ul>
						</div>
						<div class="image">
							<img src="images/machine_human.jpg" alt=""/>
						</div>
					</section>

					<section class="spotlight style1 orient-right content-align-left image-position-center onscroll-image-fade-in" id="first">
						<div class="content">
							<h2><b>Abstract</b></h2>
							<p>Traditional epidemiology techniques, most notably polygenic risk scoring, have been used by researchers and well-known companies, such as 23andMe, to calculate the disease risk of patients and consumers. However, recent research has begun to uncover limitations in such techniques due to their inability to model high dimensional data with complex interactions (Wai, 2019). As humans, millions of potentially disease-contributing genetic variants exist in our genome, so the inability to leverage such information limits the power of these techniques to accurately determine the disease risk of individuals. In this report, we explore the viability of machine learning in disease risk prediction. We show how Support Vector Machines (SVMs) outperform other popular machine learning algorithms, such as Logistic Regression, K Nearest Neighbors, Random Forest, and Naive Bayes. SVMs help address the high dimensional data issues in traditional techniques and offer an alternate and possibly better method to predict disease risk in individuals.</p>
						</div>
					</section>

				<!-- Two -->
					<section class="spotlight style1 orient-right content-align-left image-position-center onscroll-image-fade-in" id="first">
						<div class="content">
							<h2><b>Introduction</b></h2>
							<p>Genetic studies have enabled researchers and medical practitioners to better understand the underlying relationships between genes and human traits (Tian, 2019). However, these traits extend to well beyond those that are not so easily seen or determined, such as disease. This relationship between genes and diseases has been investigated through Genome Wide Association Studies (GWASs), which analyze the entire human genome to find genetic variants associated with specific traits and diseases (“Genome-Wide Association Studies,” n.d.). The genetic variants that are commonly investigated are Single Nucleotide Polymorphisms (SNPs), which are the most common form of genetic variation in the human genome. A SNP represents a single nucleotide difference in the genome. To clarify, the DNA is composed of four nucleotide bases: Thymine, Cytosine, Adenine, and Guanine. If more than 1% of the population does not have the same nucleotide at a specific position in the genome, this is then considered a SNP (“SNP,” n.d.). However, a particular SNP does not necessarily contribute towards the development of a particular disease. This is precisely the reason why GWASs are so powerful; they investigate and uncover the variants that contribute towards disease.</p>
							<p>
								After compiling results from GWASs, researchers are able to estimate the potential risk an individual has in developing a particular disease. A common method of calculating such risk is through polygenic risk scoring, which weighs SNPs according to their importance in the development of a disease and sums each risk score together. However, recent research has revealed that such a method is unable to effectively model high dimensional data (Wai, 2019). Given that the number of SNPs that contribute towards a disease can be in the thousands, this shortcoming becomes an issue. In an effort to circumvent such an issue, we plan to explore the viability of machine learning in disease risk prediction. Popular machine learning algorithms, such as Support Vector Machines, K Nearest Neighbors, Logistic Regression, Random Forest, and Naive Bayes will all be explored. Coronary Heart Disease will initially be explored and then expanded to include other diseases.
							</p>
							<p>
								Through this project we hope to answer the following research questions:<br>
								<b>1. How do machine learning techniques perform in predicting disease risk?<br>
								2. How does this performance vary across different diseases? </b>
							</p>
							<p>
								Recent research has uncovered promising results in using machine learning techniques for disease risk prediction. Currently, Support Vector Machines appear to be the most popular for its predictive power and ability to handle highly dimensional information (Uddin, 2019). We also anticipate that the eventual model will vary in performance for diseases of different complexities. In other words, diseases that have more SNPs contributing to it will be more difficult to model than those having less SNPs.
							</p>
						</div>
					</section>

				<!-- Three -->
					<section class="spotlight style1 orient-left content-align-left image-position-center onscroll-image-fade-in">
						<div class="content">
							<h2><b>Methods</b></h2>
							
							<p> <h3><b>The Data</b></h3>
								For the purposes of this project, data was acquired from the GWAS Catalog (https://www.ebi.ac.uk/gwas/). Data for {INSERT DISEASES} was all collected from this source. The data was ingested directly from the site’s public API. The GWAS Catalog is a publically available collection of Genome Wide Association Studies results, created collaboratively between EMBL-EBI and NHGRI, which contains summary statistics for the most significant SNP-disease associations found in published GWASs. To ensure the accuracy and validity of the data, the data is carefully curated by experienced molecular biologists. In addition, given that each of the GWASs is conducted independently, the individuals involved in each of these studies come from a variety of different samples and populations. For coronary heart disease, for example, which was the first disease that was examined in this project, the data is based on individuals of European, Asian, African, Middle Eastern, Native American, and other Admixed ancestries who were analyzed through statistical meta analysis techniques. Not much further information for this sample in this GWAS is provided. It should be noted that information for GWASs is typically hidden to ensure the privacy of the individuals in the study. For more information on the data being used, please visit https://www.ebi.ac.uk/gwas/docs/about. 
							</p>

							<input type="checkbox" class="read-more-state2" id="post-2" />
							<p class="read-more-wrap2">
								<span class="read-more-target2">This data is relevant to the project at hand as knowing which SNPs are the strongest indicators for the development of specific diseases is of interest. For coronary heart disease, the GWAS Catalog provides summary statistics on the most relevant SNPs to the disease. From this, exactly which SNPs to look for in an individual’s variants to better predict whether that individual is at a higher risk of coronary heart disease is known.
									<br>
									<br>
									In terms of the relationship and appropriateness of the data to our project, we will be using the columns containing information on the variant ID (SNP identifier), beta value (weight), and the corresponding risk allele frequency of SNPs. For every disease that is modeled, a total of two GWAS Catalog data sets will be collected. One of these data sets will be used for simulating a population and the other for model building. Detailed information as to why and how this is done is located in the ‘Population Simulation’ section.
								</span>
							</p>
							<label for="post-2" class="button primary read-more-trigger2" style="margin-left: 40%"></label>
							
							<p> <h3><b>Data Cleaning</b></h3>
								From the acquired GWAS result data, only the variant ID, beta value, and risk allele frequency columns were needed; the other 35 columns were subsequently discarded. Since such information was required, observations that contained missing values in these columns were removed. For example, without beta values, the SNPs are no longer useful as we do not know their contribution to a disease. In the data set that will be used for model building, all SNPs were kept as their beta values are not of interest; the model should ultimately be learning them. Interestingly, duplication of SNP and beta values appeared in each data set and were subsequently removed. After all this is done, a data frame consisting of three columns with no missing values or duplicates is created and will be used for simulating. Also, a data frame consisting of a single SNP column is created and will be used for model building.

							</p>
							<p> <h3><b>Population Simulation</b></h3>
								While gathering data, we were unable to acquire individual-level SNP data. While this data is available (Keane, 2020), data access is restricted and access was not granted. This data is critical for the project at hand as it is the foundation for training and validating the eventual model. Given that individual-level SNP data of individuals contains personally identifiable information (PII) and requesting access to this data requires someone with more scientific credentials to request access, we were unable to work with individual-level SNP data. As a solution, we created a pipeline to simulate this individual-level SNP data for multiple diseases using the information provided by the GWAS Catalog. This added component requires the collection of two sets of GWAS data sets for a particular disease; one data set is used for simulation and the other is used for model building. The model building data set will inform the model of the SNPs to consider when training. This will be discussed further in the model building section.
							</p>

							<input type="checkbox" class="read-more-state" id="post-1" />
							<p class="read-more-wrap">
								<span class="read-more-target">The first step into simulating the data is identifying the relevant SNPs (variant ID) and their contribution to a particular disease (beta score). The next step is identifying the risk allele frequencies for the SNPs. This allows us to know the frequency of a SNP in the general population.
									<br>
									<br>
										A total of 10,000 individuals were simulated for the simulation data set. Each individual was assigned an allele at each SNP position according to that SNP’s risk allele frequency in the population. For example, if the risk allele frequency of a SNP is 10%, every individual would have a 10% chance of having the alternative allele assigned to them. This is done for every SNP in the data set and repeated for all 10,000 individuals. In the end, the frequency of the SNPs in the data set closely reflect that of the initial risk allele frequencies. From there, a polygenic risk score (PRS) was assigned to each individual by taking the dot product of the beta scores and the binary SNP values. This can be described by the following formula:<br>
										<br>
										<img src="images/PRS.png" alt="" width="250" style="margin-left: 35%;"/>
									<br>
									<br>
										Where &beta;<sub>j</sub> is the beta score (weight) for the jth SNP, SNP<sub>ij</sub> is a binary value representing whether the ith 
										individual has the jth SNP. 
										The formula is followed from https://sahirbhatnagar.com/blog/2017/08/11/polygenic-risks-scores-with-data.table-in-r/.
									<br>
									<br>
										Disease risk was then assigned to each simulated individual by including a ‘bias’ step into the above simulation pipeline. In order to apply such a bias, determining what proportion of the data set should be at different risk levels and how much they should be biased by was necessary. Given that general disease trends follow a distribution where the majority of individuals are at low risk, a small portion are at medium risk, and the smallest portion are at high risk, the assignment of these classes was 60%, 30%, and 10%, respectively. In order to apply bias to each of these classes of the data set, the SNPs of those at low risk will be scaled according to a sampled value in the set of numbers between .1-.5, those at medium risk will be scaled according to a sampled value in the set of numbers between .5-.75,  and those at high risk will be scaled according to a sampled value in the set of numbers between .75-1. For example, the risk allele frequency of a particular SNP for an individual at low risk can be scaled by .3 and an individual at high risk can be scaled by .9. This method creates individuals at different disease risk levels. It should be noted that the scaled value for each disease risk level is sampled from a range of values to add variability and noise to the data set. After this is done, the data set is now ready, the class of each individual is known, and the scaled data set can be used to train a model to learn each of the classes.
								</span>
							</p>
							<label for="post-1" class="button primary read-more-trigger" style="margin-left: 40%"></label>

							<p> <h3><b>Exploratory Data Analysis (EDA)</b></h3>
								After simulating individual-level SNP data, it is important to evaluate its contents and features. For this exploration, a simulated cardiovascular disease data set will be explored. Please note that multiple diseases are included in this project; therefore, this exploration demonstrates the general contents and statistics in a simulated individual-level SNP data set. 
							</p>
							<p>
								The data set consists of 10,000 individuals, with each individual represented as one row in the data set. There are a total of 778 columns, from which 776 are individual SNPs and the remaining two are the polygenic risk score and class label columns. Each of the SNP columns contain binary values (0 and 1) representing whether an individual has the risk allele The polygenic risk score column consists of floats and the class label column consists of three integers, each of which represents a class. Given the method of simulating, the data consists of roughly 60% low risk, 30% medium risk, and 10% high risk individuals. The distribution of polygenic risk scores as a whole has a right skew (Figure 1) and the same persists when looking at the distributions at a class level. Due to the bias that was integrated into the simulation, there is a clear difference in the distribution of polygenic risk scores across the different classes (Figure 2).<br>
								<center><img src="images/distributions.png" alt="" width="650"/></center>
							</p>

							<input type="checkbox" class="read-more-state3" id="post-3" />
							<p class="read-more-wrap3">
								<span class="read-more-target3">It is also important to evaluate the minor allele frequencies (MAFs) of the SNPs as they directly influence the likelihood of an observation having a SNP and ultimately affects the eventual polygenic risk score. There is no clear shape in the distribution of minor allele frequencies as there exists much variability (Figure 3). The smallest minor allele frequency is .00039 and the largest is .498. Intuitively, one may assume that there exists a relationship between the minor allele frequency of a SNP and their contribution in developing coronary heart disease. In other words, the smaller the frequency of a SNP, the larger its influence. Although the majority of the SNPs contribute a minimal amount regardless of frequency, those that are the most influential do tend towards lower minor allele frequencies (Figure 4).
									<br>
									<br>
									<img src="images/maf.png" alt="" width="650" style="margin-left: 18%;"/>
									<br>
									<br>
									As for the model, it will only consider SNPs that were found to be associated with cardiovascular disease in the acquired GWAS data set that was designated for model building. This separate GWAS identifies a total of 709 SNPs, of which 669 are in the simulated data set. Therefore, the model will train on 669 of 776, or 86%, of the SNPs in the GWAS used to generate the data. Using this subset of features, the model will attempt to classify each individual into their respective class. 
								</span>
							</p>
							<label for="post-3" class="button primary read-more-trigger3" style="margin-left: 40%"></label>


							<p> <h3><b>Model Building</b></h3>
								During model generation, the simulated data set is treated as ‘ground truth’. This means that all the information to explain the disease risk label is in the data set; this is the case according to the way the data was simulated. If a model were trained on this data, it would be trivial as the model is given all the information to predict the label. Therefore, the acquired GWAS data set that was designated for model building is used to build the model. The second data set informs the model of which subset of SNPs to train on. For example, if the simulated data set were to have 700 SNPs but the model data set contained only 300 of those 700 SNPs (the overlap), only 300 SNPs will be used to build the model and make predictions. The aim of this process is to precisely mimic the fashion in which training data is typically structured. Training data does not typically contain all the explanatory variables that explain the label. In fact, it typically contains only a subset of the information needed. This forces the model to learn the underlying data and make informed predictions. 
							</p>
							<p>
								After the data was filtered through the process above, it was then ready for model building. We explored a variety of models and tuned their parameters in order to figure out which is best for disease risk prediction. The models we explored include Support Vector Machines, Naive Bayes, Logistic Regression, K Nearest Neighbors, Decision Trees, and Random Forest. [DISCUSS PARAMETERS]
							</p>
							<p> <h3><b>Model Validation</b></h3>
								Once the models were constructed, the results were validated. It is important to note that accuracy is not the only metric that is important to assess the performance of the models. Since we are working with predicting the disease risk of individuals, Type I and Type II errors are also very important. It is potentially dangerous to classify an individual as low risk when they are actually high risk (Type II, False Negative). Additionally, classifying an individual as high risk when they are actually low risk could cause the individual some unnecessary stress within themselves and their families (Type I, False Positive). Therefore, it is important to control for such errors in our model. To do so, we will prioritize the maximization of Recall (TP/(TP+FN)) since it is an indicator of the dangerous False Negatives in our model but at the same time attempt to maximize Precision (TP/(TP+FP)) since it is an indicator of False Positives.
							</p>
							<p>
								In general:<br>
								- <b>Accuracy</b> is a great metric only when you have symmetric datasets (meaning false negatives & false positives counts are close) and when 
								false negatives & false positives have similar costs. If the cost of false positives and false negatives are different, then F1-score is 
								the best option. F1-score is best if you have an uneven class distribution.<br>
								- <b>Recall/Sensitivity</b> is the best metric if the idea of false positives is far better than false negatives. In other words, if the occurrence 
								of false negatives is unaccepted/intolerable, then you'd rather get some extra false positives (false alarms) over saving some false negatives, 
								like in the diabetes example. In that example, you'd rather get some healthy people labeled diabetic over leaving a diabetic person labeled 
								healthy.<br>
								- <b>Precision</b> is the best metric if you want to be more confident of your true positives. For example, with spam emails, you'd rather have some 
								spam emails in your inbox rather than some regular emails in your spam box. So, the email company wants to be extra sure that email Y is spam 
								before they put it in the spam box and you never get to see it.<br>
								- <b>Specificity</b> is the best metric if you want to cover all true negatives, meaning you don't want any false alarms (false positives). For example, 
								if you're running a drug test in which all people who test positive will immediately go to jail, then you don't want anyone drug-free going to 
								jail. In this example, false positives are intolerable.
							</p>
						</div>
					</section>

				<!-- Four -->
					<section class="spotlight style1 orient-right content-align-left image-position-center onscroll-image-fade-in">
						<div class="content">
							<h2><b>Results</b></h2>
							<p>
								For each model, we got the accuracy and F1 score for the baseline model, calculated the average specificity between each of the three classes (Low Risk, 
								Medium Risk, and High Risk), and performed grid search cross validation to perform hyperparameter tuning and get the optimal set of parameters. Then, 
								we plotted Receiver Operating Characteristic (ROC) and Precision-Recall (P-R) curves to provide a visual way of comparing each model’s results. For 
								context, an ROC curve is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is 
								varied. The ROC curve is created by plotting the true positive rate against the false positive rate at various threshold settings. A P-R curve is a plot 
								of the precision (y-axis) and the recall (x-axis) for different thresholds, much like the ROC curve. Essentially, for an ROC curve, as the curve moves higher 
								up and to the left, the better the model performs for a particular class since the true positive rate is maximized and the false positive rate is minimized 
								across various thresholds. Similarly, for a P-R curve, as the curve moves higher up and to the right, the better the model performs for a particular class 
								since both precision and recall are maximized across various thresholds.  Here are the ROC and P-R curves for each model:
							</p>

						</div>
					</section>
						<!-- Gallery -->
						<div class="gallery style2 medium lightbox onscroll-fade-in">
							<article>
								<a href="images/gallery/lr_pr.png" class="image">
									<img src="images/gallery/lr_pr.png" alt="" />
								</a>
								<div class="caption">
									<h3>Logistic Regression</h3><br>
									<h3>Precision & Recall</h3>
									<br>
									<ul class="actions fixed">
										<li><span class="button small">View</span></li>
									</ul>
								</div>
							</article>
							<article>
								<a href="images/gallery/lr_roc.png" class="image">
									<img src="images/gallery/lr_roc.png" alt="" />
								</a>
								<div class="caption">
									<h3>Logistic Regression</h3><br>
									<h3>ROC Curve</h3>
									<br>
									<ul class="actions fixed">
										<li><span class="button small">View</span></li>
									</ul>
								</div>
							</article>
							<article>
								<a href="images/gallery/knn_pr.png" class="image">
									<img src="images/gallery/knn_pr.png" alt="" />
								</a>
								<div class="caption">
									<h3>K Nearest Neighbors</h3><br>
									<h3> Precision & Recall</h3>
									<br>
									<ul class="actions fixed">
										<li><span class="button small">View</span></li>
									</ul>
								</div>
							</article>
							<article>
								<a href="images/gallery/knn_roc.png" class="image">
									<img src="images/gallery/knn_roc.png" alt="" />
								</a>
								<div class="caption">
									<h3>K Nearest Neighbors</h3><br>
									<h3>ROC Curve</h3>
									<br>
									<ul class="actions fixed">
										<li><span class="button small">View</span></li>
									</ul>
								</div>
							</article>
							<article>
								<a href="images/gallery/svm_pr.png" class="image">
									<img src="images/gallery/svm_pr.png" alt="" />
								</a>
								<div class="caption">
									<h3>Support Vector Machine</h3><br>
									<h3>Precision & Recall</h3>
									<br>
									<ul class="actions fixed">
										<li><span class="button small">View</span></li>
									</ul>
								</div>
							</article>
							<article>
								<a href="images/gallery/svm_roc.png" class="image">
									<img src="images/gallery/svm_roc.png" alt="" />
								</a>
								<div class="caption">
									<h3>Support Vector Machine</h3><br>
									<h3>ROC Curve</h3>
									<br>
									<ul class="actions fixed">
										<li><span class="button small">View</span></li>
									</ul>
								</div>
							</article>
							<article>
								<a href="images/gallery/nb_pr.png" class="image">
									<img src="images/gallery/nb_pr.png" alt="" />
								</a>
								<div class="caption">
									<h3>Naive Bayes</h3><br>
									<h3>Precision & Recall</h3>
									<br>
									<ul class="actions fixed">
										<li><span class="button small">View</span></li>
									</ul>
								</div>
							</article>
							<article>
								<a href="images/gallery/nb_roc.png" class="image">
									<img src="images/gallery/nb_roc.png" alt="" />
								</a>
								<div class="caption">
									<h3>Naive Bayes</h3><br>
									<h3>ROC Curve</h3>
									<br>
									<ul class="actions fixed">
										<li><span class="button small">View</span></li>
									</ul>
								</div>
							</article>
							<article>
								<a href="images/gallery/rf_pr.png" class="image">
									<img src="images/gallery/rf_pr.png" alt="" />
								</a>
								<div class="caption">
									<h3>Random Forest</h3><br>
									<h3>Precision & Recall</h3>
									<br>
									<ul class="actions fixed">
										<li><span class="button small">View</span></li>
									</ul>
								</div>
							</article>
							<article>
								<a href="images/gallery/rf_roc.png" class="image">
									<img src="images/gallery/rf_roc.png" alt="" />
								</a>
								<div class="caption">
									<h3>Random Forest</h3><br>
									<h3>ROC Curve</h3>
									<br>
									<ul class="actions fixed">
										<li><span class="button small">View</span></li>
									</ul>
								</div>
							</article>
							<article>
								<a href="images/gallery/dt_pr.png" class="image">
									<img src="images/gallery/dt_pr.png" alt="" />
								</a>
								<div class="caption">
									<h3>Decision Tree</h3><br>
									<h3>Precision & Recall</h3>
									<br>
									<ul class="actions fixed">
										<li><span class="button small">View</span></li>
									</ul>
								</div>
							</article>
							<article>
								<a href="images/gallery/dt_roc.png" class="image">
									<img src="images/gallery/dt_roc.png" alt="" />
								</a>
								<div class="caption">
									<h3>Decision Tree</h3><br>
									<h3>ROC Curve</h3>
									<br>
									<ul class="actions fixed">
										<li><span class="button small">View</span></li>
									</ul>
								</div>
							</article>
						</div>
					<section class="spotlight style1 orient-right content-align-left image-position-center onscroll-image-fade-in">
						<div class="content">
							<p>
								After running each model, we compiled the model results into a dataframe that contains each model’s accuracy, F1 score, and average specificity for both 
								the baseline model and grid search optimized model. Here is the dataframe:<br>
								<center><img src="images/model_results.png" alt="" width="800"/></center>
							</p>
							<p>
								From our results, we find that Support Vector Machine performed the best on every metric by having 100% for each metric. We determined that the SVM was 
								genuinely performing the best by extracting meaningful features rather than overfitting to our data set. However, it may be taking advantage of the way 
								in which the data was simulated (to be explored further). Naive Bayes and Random Forest also performed really well and could be great alternative models 
								to use in our project.
							</p>
						</div>
					</section>

				<!-- Five -->
					<section class="wrapper style1 align-left">
						<div class="inner">
							<h2><b>Conclusion</b></h2>
							<p>Because Support Vector Machine performed the best out of the various models, we decided to use SVM as our model for disease prediction, at least when we 
								worked with coronary heart disease data. We will continue to explore other diseases to get a better understanding of each model’s performance in disease 
								prediction.</p>
						</div>
					</section>

					<section class="wrapper style1 align-left">
						<div class="inner">
							<h2>Source Code</h2>
							<p>
								Source code and detailed Jupyter notebooks can be accessed <a href="https://github.com/esanchez01/PredictingDisease" target="_blank">here</a>.
							</p>
						</div>
					</section>

				<!-- Six -->
					<section class="wrapper style1 align-left">
						<div class="inner">
							<h2>References</h2>
							<p>
								1. Cáceres, J. J., & Paccanaro, A. (2019, July 5). Disease gene prediction for molecularly uncharacterized diseases. Retrieved from
								 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6636748/
							</p>
							<p>
								2. Genome-Wide Association Studies (GWAS). (n.d.). Retrieved from https://www.genome.gov/genetics-glossary/Genome-Wide-Association-Studies
							</p>
							<p>
								3. Schrodi, S. J., Mukherjee, S., Shan, Y., Tromp, G., Sninsky, J. J., Callear, A. P., … Weeks, D. E. (2014, June 2). Genetic-based prediction 
								of disease traits: prediction is very difficult, especially about the future. Retrieved from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4040440/
							</p>
							<p>
								4. SNP. (n.d.). Retrieved May 17, 2020, from https://www.nature.com/scitable/definition/snp-295/
							</p>
							<p>
								5. Uddin, S. (2019, December 21). Comparing different supervised machine learning algorithms for disease prediction. Retrieved May 17, 2020, 
								from https://bmcmedinformdecismak.biomedcentral.com/articles/10.1186/s12911-019-1004-8
							</p>
							<p>
								6. Wai, D. S., William, Melissa, Richard, O’Sullivan, & Justin. (2019, March 11). Machine Learning SNP Based Prediction for Precision Medicine.
								Retrieved May 17, 2020, from https://www.frontiersin.org/articles/10.3389/fgene.2019.00267/full
							</p>
							<p>
								7. Wray, N. R., Yang, J., Hayes, B. J., Price, A. L., Goddard, M. E., & Visscher, P. M. (2013, July). Pitfalls of predicting complex traits from
								SNPs. Retrieved from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4096801/
							</p>
						</div>
					</section>

				<!-- Footer -->
					<footer class="wrapper style1 align-center">
						<div class="inner">
							<p>&copy; UCSD 2020.</p>
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>